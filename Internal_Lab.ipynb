{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dLNmH00gjIhB"
      },
      "outputs": [],
      "source": [
        "# ============================================\n",
        "# ðŸ“Œ Q1: Simple Linear Regression\n",
        "# ============================================\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Dataset\n",
        "X = np.array([[1], [2], [3], [4], [5]])\n",
        "y = np.array([3, 6, 7, 8, 11])\n",
        "\n",
        "# Train model\n",
        "lin_model = LinearRegression()\n",
        "lin_model.fit(X, y)\n",
        "\n",
        "# Predictions\n",
        "y_pred = lin_model.predict(X)\n",
        "\n",
        "print(\"Coefficient:\", lin_model.coef_)\n",
        "print(\"Intercept:\", lin_model.intercept_)\n",
        "print(\"Predicted values:\", y_pred)\n",
        "\n",
        "\n",
        "# ============================================\n",
        "# ðŸ“Œ Q2: Logistic Regression\n",
        "# ============================================\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Dataset\n",
        "X = np.array([[1], [2], [3], [4], [5], [6]])\n",
        "y = np.array([0, 0, 0, 1, 1, 1])\n",
        "\n",
        "log_model = LogisticRegression()\n",
        "log_model.fit(X, y)\n",
        "\n",
        "y_pred = log_model.predict(X)\n",
        "y_prob = log_model.predict_proba(X)\n",
        "\n",
        "print(\"Coefficient:\", log_model.coef_)\n",
        "print(\"Intercept:\", log_model.intercept_)\n",
        "print(\"Predicted labels:\", y_pred)\n",
        "print(\"Predicted probabilities:\", y_prob)\n",
        "\n",
        "\n",
        "# ============================================\n",
        "# ðŸ“Œ Q3: Preprocessing (Manual)\n",
        "# ============================================\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Dataset\n",
        "data = pd.DataFrame({\n",
        "    'age': [25, 30, np.nan, 40, 35],\n",
        "    'salary': [50000, 60000, 55000, np.nan, 65000],\n",
        "    'city': ['Delhi', 'Mumbai', 'Delhi', 'Chennai', 'Mumbai'],\n",
        "    'target': [0, 1, 0, 1, 1]\n",
        "})\n",
        "\n",
        "X = data[['age', 'salary', 'city']]\n",
        "y = data['target']\n",
        "\n",
        "# Numeric preprocessing\n",
        "num_features = ['age', 'salary']\n",
        "imputer_num = SimpleImputer(strategy='mean')\n",
        "X_num = imputer_num.fit_transform(X[num_features])\n",
        "scaler = StandardScaler()\n",
        "X_num = scaler.fit_transform(X_num)\n",
        "\n",
        "# Categorical preprocessing\n",
        "cat_features = ['city']\n",
        "imputer_cat = SimpleImputer(strategy='most_frequent')\n",
        "X_cat = imputer_cat.fit_transform(X[cat_features])\n",
        "encoder = OneHotEncoder(handle_unknown='ignore')\n",
        "X_cat = encoder.fit_transform(X_cat).toarray()\n",
        "\n",
        "# Combine\n",
        "X_processed = np.hstack((X_num, X_cat))\n",
        "print(\"Processed feature matrix shape:\", X_processed.shape)\n",
        "\n",
        "\n",
        "# ============================================\n",
        "# ðŸ“Œ Q4: Class Imbalance\n",
        "# ============================================\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Dataset\n",
        "X = np.array([[1], [2], [3], [4], [5], [6], [7], [8], [9], [10]])\n",
        "y = np.array([0, 0, 0, 0, 0, 0, 0, 1, 1, 1])\n",
        "\n",
        "print(\"Class distribution:\", Counter(y))\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "imb_model = LogisticRegression(class_weight='balanced')\n",
        "imb_model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = imb_model.predict(X_test)\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "\n",
        "# ============================================\n",
        "# ðŸ“Œ Q5: PCA (Dimensionality Reduction)\n",
        "# ============================================\n",
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Dataset: random 50 samples with 4 features\n",
        "X = np.random.rand(50, 4)\n",
        "\n",
        "pca = PCA(n_components=2)\n",
        "X_pca = pca.fit_transform(X)\n",
        "\n",
        "print(\"Explained variance ratio:\", pca.explained_variance_ratio_)\n",
        "\n",
        "plt.scatter(X_pca[:, 0], X_pca[:, 1])\n",
        "plt.title(\"PCA Projection to 2D\")\n",
        "plt.xlabel(\"PC1\")\n",
        "plt.ylabel(\"PC2\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# ============================================\n",
        "# ðŸ“Œ Q6: Support Vector Machine (SVM)\n",
        "# ============================================\n",
        "from sklearn import datasets\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "iris = datasets.load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "svm_model = SVC(kernel='linear')\n",
        "svm_model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = svm_model.predict(X_test)\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "\n",
        "# ============================================\n",
        "# ðŸ“Œ Q7: Clustering (KMeans)\n",
        "# ============================================\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# Dataset\n",
        "X = np.array([[1,2], [1,3], [2,2], [8,8], [9,9], [8,9]])\n",
        "\n",
        "kmeans = KMeans(n_clusters=3, random_state=42)\n",
        "kmeans.fit(X)\n",
        "\n",
        "labels = kmeans.labels_\n",
        "centers = kmeans.cluster_centers_\n",
        "\n",
        "print(\"Cluster centers:\\n\", centers)\n",
        "\n",
        "plt.scatter(X[:, 0], X[:, 1], c=labels, cmap='viridis')\n",
        "plt.scatter(centers[:, 0], centers[:, 1], c='red', marker='x', s=200, label='Centers')\n",
        "plt.title(\"KMeans Clustering\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# ============================================\n",
        "# ðŸ“Œ Q8: Decision Trees\n",
        "# ============================================\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "\n",
        "iris = datasets.load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "dt_model = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
        "dt_model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = dt_model.predict(X_test)\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "plt.figure(figsize=(12,8))\n",
        "plot_tree(dt_model, feature_names=iris.feature_names, class_names=iris.target_names, filled=True)\n",
        "plt.title(\"Decision Tree (Iris Dataset)\")\n",
        "plt.show()"
      ]
    }
  ]
}